{"cells":[{"cell_type":"markdown","metadata":{"id":"JSqT4VKfE31G"},"source":["# **LSTM - Movie Sentiment Analysis** "]},{"cell_type":"markdown","metadata":{"id":"foRdHh7yEpzu"},"source":["## **0. Settings**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1578,"status":"ok","timestamp":1643851858807,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"aqQhtJaEEAhd","outputId":"baeb6265-2ff8-4206-e207-be85e9136ef6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7C6Qq1ArEQn8"},"outputs":[],"source":["#import all used library\n","import pandas as pd # read datasets\n","\n","# libraries to load datasets and handle models \n","import torch\n","import numpy as np \n","from collections import Counter\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","\n","# time management \n","import os\n","import time\n","import datetime\n","\n","# plotting \n","import matplotlib.pyplot as pyplot\n","\n","# math lib \n","import math"]},{"cell_type":"markdown","metadata":{"id":"HF4L8g0lKM1Z"},"source":["## **1. Prepare Data for the Training Model**"]},{"cell_type":"markdown","metadata":{"id":"QbgZoI8OP6tp"},"source":["### **1.1. Import and Classify Data**"]},{"cell_type":"markdown","metadata":{"id":"ELXv_t6tRnA8"},"source":["The data in IMDB Review Dataset is structured into a .csv file that allows us to construct a pandas dataframe out of the data. The dataframe consists of five columns: *No, type, review, label, file*. The data is classified into two different types *train* and *test* to facilitate the training and testing processes. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LQ5WZLkEfKs"},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/MyDrive/NLP2022/movie_sentiments/data/imdb_master.csv\", encoding='unicode_escape')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1643851863831,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"6mnFaJUUHlft","outputId":"7aa73d07-67bb-4f4f-a686-4c98dfcc05bf"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-259ef656-d656-4e2d-ba4a-fffb3e2e34f5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>type</th>\n","      <th>review</th>\n","      <th>label</th>\n","      <th>file</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>test</td>\n","      <td>Once again Mr. Costner has dragged out a movie...</td>\n","      <td>neg</td>\n","      <td>0_2.txt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>test</td>\n","      <td>This is an example of why the majority of acti...</td>\n","      <td>neg</td>\n","      <td>10000_4.txt</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>test</td>\n","      <td>First of all I hate those moronic rappers, who...</td>\n","      <td>neg</td>\n","      <td>10001_1.txt</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>test</td>\n","      <td>Not even the Beatles could write songs everyon...</td>\n","      <td>neg</td>\n","      <td>10002_3.txt</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>test</td>\n","      <td>Brass pictures (movies is not a fitting word f...</td>\n","      <td>neg</td>\n","      <td>10003_3.txt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-259ef656-d656-4e2d-ba4a-fffb3e2e34f5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-259ef656-d656-4e2d-ba4a-fffb3e2e34f5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-259ef656-d656-4e2d-ba4a-fffb3e2e34f5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0  type  ... label         file\n","0           0  test  ...   neg      0_2.txt\n","1           1  test  ...   neg  10000_4.txt\n","2           2  test  ...   neg  10001_1.txt\n","3           3  test  ...   neg  10002_3.txt\n","4           4  test  ...   neg  10003_3.txt\n","\n","[5 rows x 5 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1643851863832,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"fbIpNBZhIde3","outputId":"a0901611-b109-4e4c-fe62-bf4329835851"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ab595c54-3ceb-48f9-8aa3-5ce913c8400b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>type</th>\n","      <th>review</th>\n","      <th>label</th>\n","      <th>file</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>99995</th>\n","      <td>99995</td>\n","      <td>train</td>\n","      <td>Delightfully awful! Made by David Giancola, a ...</td>\n","      <td>unsup</td>\n","      <td>9998_0.txt</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>99996</td>\n","      <td>train</td>\n","      <td>Watching Time Chasers, it obvious that it was ...</td>\n","      <td>unsup</td>\n","      <td>9999_0.txt</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>99997</td>\n","      <td>train</td>\n","      <td>At the beginning we can see members of Troma t...</td>\n","      <td>unsup</td>\n","      <td>999_0.txt</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>99998</td>\n","      <td>train</td>\n","      <td>The movie was incredible, ever since I saw it ...</td>\n","      <td>unsup</td>\n","      <td>99_0.txt</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>99999</td>\n","      <td>train</td>\n","      <td>TCM came through by acquiring this wonderful, ...</td>\n","      <td>unsup</td>\n","      <td>9_0.txt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab595c54-3ceb-48f9-8aa3-5ce913c8400b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab595c54-3ceb-48f9-8aa3-5ce913c8400b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab595c54-3ceb-48f9-8aa3-5ce913c8400b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       Unnamed: 0   type  ...  label        file\n","99995       99995  train  ...  unsup  9998_0.txt\n","99996       99996  train  ...  unsup  9999_0.txt\n","99997       99997  train  ...  unsup   999_0.txt\n","99998       99998  train  ...  unsup    99_0.txt\n","99999       99999  train  ...  unsup     9_0.txt\n","\n","[5 rows x 5 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.tail()"]},{"cell_type":"markdown","metadata":{"id":"To4TU3gHTEsZ"},"source":["We are interested in the data with predefined labels *pos* and *neg*, and so we will extract only the data with these labels. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axb3ujGEIuDt"},"outputs":[],"source":["data = data[(data.label == \"pos\") | (data.label == \"neg\")]  # only use reviews with either a pos or a neg label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2RqJLjrJ_IK"},"outputs":[],"source":["#train_data = data[data[\"type\"] == \"train\"]  # classify data by train and test types\n","#test_data = data[data[\"type\"] == \"test\"]\n","#train = train_data.iloc[:,2:4]  # delete the first two columns and the last column, retaining columns 'review' and 'label'\n","#test = test_data.iloc[:,2:4]"]},{"cell_type":"markdown","metadata":{"id":"3_64pVxJSd8P"},"source":["Next, we want to delete redundant columns and only retain columns *'review'* and *'label'*. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyiDBhviJz_V"},"outputs":[],"source":["data = data.iloc[:,2:4]  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1643851863835,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"Sz_aeZHnJ1Ay","outputId":"d30149f7-90e9-459a-cd7a-e4ab8b1724ff"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0e9f6821-49ec-451d-adaa-4230d10d7f43\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Once again Mr. Costner has dragged out a movie...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This is an example of why the majority of acti...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>First of all I hate those moronic rappers, who...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Not even the Beatles could write songs everyon...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Brass pictures (movies is not a fitting word f...</td>\n","      <td>neg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e9f6821-49ec-451d-adaa-4230d10d7f43')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0e9f6821-49ec-451d-adaa-4230d10d7f43 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0e9f6821-49ec-451d-adaa-4230d10d7f43');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              review label\n","0  Once again Mr. Costner has dragged out a movie...   neg\n","1  This is an example of why the majority of acti...   neg\n","2  First of all I hate those moronic rappers, who...   neg\n","3  Not even the Beatles could write songs everyon...   neg\n","4  Brass pictures (movies is not a fitting word f...   neg"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"QRJvwXRnP0hW"},"source":["### **1.2. Shuffle Data**"]},{"cell_type":"markdown","metadata":{"id":"DtAV6QgNS2OM"},"source":["Since the dataset is currently arranged in an alphabetical order, it is important to shuffle the dataset so as to avoid any pattern that can affect the learning process. This is a basic rule in training deep learning model.\n","\n","Particularly, if we divide the dataset into training set and validating set: about 1000 last words will be assigned into validating set. This could cause an unexpected scenario: the developed model could perform significantly bad on words beginning with 'y' or 'z' because it has never been trained to predict words like that."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-EFT5lrLl9n"},"outputs":[],"source":["data = data.sample(frac = 1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1643851863836,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"5_ujcVQXRhva","outputId":"c220e3e0-8473-4034-fcad-31cd0cd16611"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-47026a8e-e2ad-4c9f-8a36-b3465559c607\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Cast to die for in a movie that is considerabl...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The production value of AvP2 can be described ...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>When I learned of Sir Alec Guinness' death, th...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Alexandra Ripley wrote a horrible sequel to Ma...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A talented high school graduating senior with ...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47026a8e-e2ad-4c9f-8a36-b3465559c607')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-47026a8e-e2ad-4c9f-8a36-b3465559c607 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-47026a8e-e2ad-4c9f-8a36-b3465559c607');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              review label\n","0  Cast to die for in a movie that is considerabl...   neg\n","1  The production value of AvP2 can be described ...   neg\n","2  When I learned of Sir Alec Guinness' death, th...   pos\n","3  Alexandra Ripley wrote a horrible sequel to Ma...   neg\n","4  A talented high school graduating senior with ...   pos"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"OKIp-zsDkVBv"},"source":["### **1.3. Standardize Data**"]},{"cell_type":"markdown","metadata":{"id":"4MWrv6d7k06c"},"source":["This step transforms words into lowercase ones and then removes punctuations and break signs from each review in the *review* column. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYN4bLKKnrSz"},"outputs":[],"source":["def standardizeData(input_column):\n","    punctuations = ['\"', '!', '#', '$', '&', '\\'' , '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '{', '|', '}', '~' ]\n","    standardized_column = []\n","    for review in input_column: \n","        review = review.lower()\n","        review = review.replace('<br />', ' ')\n","        for punc in punctuations: \n","            review = review.replace(punc, ' ')\n","        standardized_column.append(review)\n","    return standardized_column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_VAvQ5cJfJ9"},"outputs":[],"source":["data.review = standardizeData(data.review)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1643851864562,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"yEh9WkksKBZI","outputId":"fa7de022-51eb-4d6e-fa08-fc16eca67c04"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-eebf403c-9381-4b85-a509-da46650e7377\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cast to die for in a movie that is considerabl...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the production value of avp2 can be described ...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>when i learned of sir alec guinness  death  th...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>alexandra ripley wrote a horrible sequel to ma...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a talented high school graduating senior with ...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eebf403c-9381-4b85-a509-da46650e7377')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eebf403c-9381-4b85-a509-da46650e7377 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eebf403c-9381-4b85-a509-da46650e7377');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              review label\n","0  cast to die for in a movie that is considerabl...   neg\n","1  the production value of avp2 can be described ...   neg\n","2  when i learned of sir alec guinness  death  th...   pos\n","3  alexandra ripley wrote a horrible sequel to ma...   neg\n","4  a talented high school graduating senior with ...   pos"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"id":"QRUXgvpXmyAy"},"source":["## **2. \bConvert Words to Tensors**"]},{"cell_type":"markdown","metadata":{"id":"IIsYkmqDUwvP"},"source":["### **2.1 Build a Dictionary of Words to Integers**"]},{"cell_type":"markdown","metadata":{"id":"c7m4qgfwTqwR"},"source":["Firstly, we convert the data into a Python list. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNxyA0V-KijO"},"outputs":[],"source":["list_of_reviews = list(data[\"review\"])\n","list_of_labels = list(data[\"label\"])"]},{"cell_type":"markdown","metadata":{"id":"M7j78jMzT5B6"},"source":["Next, we construct a list of words from all of the reviews and count the frequency of each word using Counter. Counter gives us a mapping of words that appear in the word list to their frequency in the corpus. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CECWYwFiQX1"},"outputs":[],"source":["corpus = ' '.join(list_of_reviews)\n","words = corpus.split()\n","\n","words_freq_dict = Counter(words)"]},{"cell_type":"markdown","metadata":{"id":"moC7_f61UmCn"},"source":["The corpus is made up of user-written reviews that may contain typos, slangs, etc. Thus, we will focus on the 30,000 most common words in the word list. The Counter object offers the method *most_common(n)* that returns the *n* most popular words in the dictionary. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1643851868756,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"d1mILUKlPK6a","outputId":"f41a7a73-5710-4371-d06a-b556cb2c3adc"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('the', 667989), ('and', 324427), ('a', 322969), ('of', 289405), ('to', 268119), ('is', 211082), ('it', 190735), ('in', 186778), ('i', 175534), ('this', 150997)]\n","[('eek', 8), ('rediscovery', 8), ('solidifies', 8), ('compulsively', 8), ('specs', 8), ('minutiae', 8), ('attal', 8), ('clearest', 8), ('somersaults', 8), ('foreheads', 8)]\n"]}],"source":["vocab_list = words_freq_dict.most_common(29999)\n","print(vocab_list[:10])\n","print(vocab_list[-10:])"]},{"cell_type":"markdown","metadata":{"id":"jdsbv7KaVMOs"},"source":["The list of the last 10 words in the *vocab_list* (consisting of 30,000 most common words) shows that words in our vocabulary have to appear at least 8 times. This helps us avoid unfamiliar words or typos. \n","\n","Next, we construct a dictionary that maps each word in our vocab list to an integer. For any word that is not included in our vocab, we assign a 0 representing a *OOV (out of vocab)* word. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mi-4DNMrItnN"},"outputs":[],"source":["word_to_int = {word_freq_tuple[0]: id for id, word_freq_tuple in enumerate(vocab_list, 1)}\n","word_to_int['OOV'] = 0"]},{"cell_type":"markdown","metadata":{"id":"Q1CZZw2AU70_"},"source":["### **2.2. Convert each review to a list of ints representing words** "]},{"cell_type":"markdown","metadata":{"id":"dgk8zfIXV49-"},"source":["Now, as we have a dictionary of words to integers for our corpus, we want to construct a LoL of reviews, each inner list of which is a vector of integers representing words in each review. For any word that is not included in our vocab, we assign a 0 representing a OOV (out of vocab) word."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJwOaJ4-QJkh"},"outputs":[],"source":["wordID_vector_by_review = []\n","\n","for review in list_of_reviews:\n","    wordID_vector = [word_to_int[word] if word in word_to_int else 0 for word in review.split()] # list of ints representing words in the review\n","                                                                                                 # id = 0 if word = OOV \n","    wordID_vector_by_review.append(wordID_vector)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1643851873363,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"XhcruUpyWD0p","outputId":"be5beee2-60ef-46df-c671-ebdf3dd03cdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[178, 5, 716, 16, 8, 3, 15, 11, 6, 5642, 341, 6620, 7751, 6, 1672, 18, 162, 54, 268, 54, 827, 5, 378, 42, 3067, 1, 63, 4, 42, 113, 2, 4, 42, 1003, 110, 10, 6, 28, 4, 146, 98, 61, 46, 1, 166, 2, 1410, 4, 109, 3, 80, 19, 332, 84, 32, 27, 36, 107, 80, 150, 2, 1507, 8, 7, 36, 7, 186, 5, 29, 44, 138, 77, 72, 1, 13953, 11, 7, 64, 6, 23, 74, 14, 139, 18, 17, 7751, 6250, 10316, 3587, 500, 4751, 3804, 18604, 5489, 9134, 5552, 10529, 13735, 2337, 2347, 4680, 8724, 2, 401, 30, 734, 487, 369, 20, 526, 52, 72, 3, 17699, 63, 1596, 3, 224, 52, 72, 3, 22962, 873, 850, 16, 1897], [1, 354, 1086, 4, 0, 50, 29, 2089, 33, 28, 16917, 374, 1, 226, 6, 642, 59, 8, 1, 2966, 1591, 4, 16578, 47, 25, 1, 0, 49, 16, 22, 1, 3361, 12, 1366, 134, 6, 1, 3361, 6139, 55, 30, 3832, 4, 26, 2389, 2, 72, 3150, 3441, 57, 17, 0, 2, 59, 5383, 1, 639, 4, 34, 9044, 394, 919, 134, 6, 1, 3361, 617, 134, 6, 1, 3361, 0, 316, 62, 22, 688, 18, 22, 26, 345, 1284, 134, 125, 1, 3361, 94, 26, 296, 36, 8262, 16, 316, 33, 3362, 177, 1, 2042, 250, 72, 7295, 1, 221, 4233, 38, 1, 1844, 78, 8, 1, 128, 134, 6, 1, 3361, 4816, 52, 52, 4, 26, 173, 2614, 250, 72, 8875, 93, 5, 391, 93, 297, 100, 780, 28, 8, 1, 128, 24, 6, 59, 4816, 26, 8876, 162, 993, 1, 0, 8, 522, 5, 522, 3805, 47, 3, 74, 14757, 4, 1, 86, 9846, 471, 554, 200, 0, 2, 1, 3361, 1, 3361, 12, 6805, 25, 36, 3914, 11, 24, 6, 707, 52, 38, 3, 925, 28241, 72, 38, 542, 6860, 19598, 14758, 1983, 14, 28, 50, 65, 1215, 1, 221, 63, 6, 3, 948, 18, 7, 217, 59, 432, 84, 10, 8954, 55, 296, 6, 1056, 55, 17, 351, 17287, 4, 4943, 12673, 38, 3, 5235, 6905, 14217, 399, 40, 48, 3635, 1512, 44, 1, 1770, 508, 4, 1, 106, 1115, 5734, 7137, 1, 2087, 6, 4, 265, 1, 427, 4, 133, 106, 2934, 35, 24, 1393, 6407, 514, 5490, 23, 1082, 422, 7928, 16, 1, 111, 8, 1660, 5, 11, 1, 178, 4, 150, 6, 492, 1097, 5, 1, 299, 701, 4, 954, 150, 4, 1, 1100, 2042, 40, 3361, 98, 0, 6, 34, 6806, 74, 415, 4, 585, 31, 237, 1, 205, 4, 1, 15, 6, 64, 334, 39, 6, 23, 3, 681, 130, 4, 205, 3805, 8, 61, 1, 302, 50, 65, 1, 221, 267, 253, 2, 172, 554, 6, 745, 8, 335, 5583, 9045, 17, 500, 55, 8802, 31, 800, 364, 2305, 11, 2003, 8, 34, 2674, 556, 16, 1, 302, 84, 28, 50, 659, 65, 164, 18, 3, 456, 5583, 257, 9, 1466, 1, 106, 967, 1115, 0, 5, 779, 529, 3, 0, 2, 75, 3, 2060, 8, 680, 4681, 36, 11, 1, 367, 19, 1387, 48, 4944, 205, 4, 4944, 2682, 2, 231, 23, 363, 5, 5794, 66, 74, 967, 3711, 8, 139, 3, 1411, 9, 60, 4297, 1688, 59, 716, 251, 16578, 457, 452, 149, 10, 19, 2622, 1, 86, 28, 40, 1, 211, 2042, 40, 1, 211, 3361, 105, 18, 788, 1323, 633, 33, 3150, 126, 3441, 57, 22, 10, 2056]]\n"]}],"source":["print(wordID_vector_by_review[:2])"]},{"cell_type":"markdown","metadata":{"id":"AvD1BS_PWm8R"},"source":["As we can tell from the first two vectors, their sizes are not the same. What about the other review in the LoL? We can visualize this using a histogram as below: "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1643851873364,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"F5nvnlIGXN9O","outputId":"240298e4-0e73-4f25-e821-7a5fc51aaeb1"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["count    50000.000000\n","mean       235.562980\n","std        174.393214\n","min          6.000000\n","25%        129.000000\n","50%        177.000000\n","75%        286.000000\n","max       2505.000000\n","dtype: float64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","review_len = [len(vector) for vector in wordID_vector_by_review]\n","pd.Series(review_len).hist()\n","plt.show()\n","pd.Series(review_len).describe()"]},{"cell_type":"markdown","metadata":{"id":"D9zA1OonW2Ex"},"source":["Among 50,000 reviews in the dataset, the mean number of words is around 235, while the min is 6 words and the max is 2505 words in a review. The distribution of number of words in the reviews is greatly skewed right with only a small number of reviews having more than 500 words.  "]},{"cell_type":"markdown","metadata":{"id":"JZfo_gHvYDk2"},"source":["### **2.3. Padding/Truncating Reviews** "]},{"cell_type":"markdown","metadata":{"id":"XqUKefxWYTjt"},"source":["With such large variations in the number of words in each review, it is important to have all vectors in the same shape so as to utilize the properties of matrices. One solution for this problem is to pad or truncate the reviews. In this case, padding should be used.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gINaw72BX773"},"outputs":[],"source":["def pad_reviews(reviews, desired_vector_length):\n","    features = np.zeros((len(reviews), desired_vector_length), dtype=int)\n","\n","    for id, review in enumerate(reviews):\n","        features[id, -len(review):] = np.array(review)[:desired_vector_length]\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLahCAzAZfTi"},"outputs":[],"source":["features = pad_reviews(wordID_vector_by_review, 235)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1643851874908,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"jYh6c2-EbWJF","outputId":"f56ed85d-ac35-4b6f-bc35-b26bc361081e"},"outputs":[{"data":{"text/plain":["(50000, 235)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["features.shape "]},{"cell_type":"markdown","metadata":{"id":"0STVbSn_cD0C"},"source":["### **2.4. Partition Data into Training, Validation, and Test Set**"]},{"cell_type":"markdown","metadata":{"id":"9CmvvQvRZoZm"},"source":["We select 9/10 of the corpus (45,000 reviews) to be training set, one half of the remaining (1/20 or 2,500 reviews) to be the validation set, and the remaining reviews (2,500 reviews) to be the test set. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brlGGEBAbrrs"},"outputs":[],"source":["split_frac = 0.9\n","last_training_index = int(len(features) * split_frac)\n","\n","train_features, remaining_features = features[:last_training_index], features[last_training_index:]\n","\n","labels_to_numbers = [1 if label == \"pos\" else 0 for label in list_of_labels]\n","labels = np.array(labels_to_numbers)\n","train_labels, remaining_labels = labels[:last_training_index], labels[last_training_index:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQTzIXvE0UwX"},"outputs":[],"source":["validation_test_frac = 0.5\n","last_validation_index = int(len(remaining_features) * validation_test_frac)\n","\n","val_features, test_features = remaining_features[:last_validation_index], remaining_features[last_validation_index:]\n","val_labels, test_labels = remaining_labels[:last_validation_index], remaining_labels[last_validation_index:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1643851874909,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"dp_wdSFG1SFS","outputId":"7df9f9f7-437a-4446-d33a-b1b1a6998320"},"outputs":[{"name":"stdout","output_type":"stream","text":["\t\t\tFeature Shapes:\n","Train set: \t\t(45000, 235) \n","Validation set: \t(2500, 235) \n","Test set: \t\t(2500, 235)\n"]}],"source":["## print out the shapes of your resultant feature data\n","print(\"\\t\\t\\tFeature Shapes:\")\n","print(\"Train set: \\t\\t{}\".format(train_features.shape), \n","      \"\\nValidation set: \\t{}\".format(val_features.shape),\n","      \"\\nTest set: \\t\\t{}\".format(test_features.shape))"]},{"cell_type":"markdown","metadata":{"id":"PPZhhhaA1kEf"},"source":["### **2.5. Construct Tensor Datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3I6kRYu1Smu"},"outputs":[],"source":["# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(train_features), torch.from_numpy(train_labels))\n","valid_data = TensorDataset(torch.from_numpy(val_features), torch.from_numpy(val_labels))\n","test_data = TensorDataset(torch.from_numpy(test_features), torch.from_numpy(test_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nQIr4lg2Gvq"},"outputs":[],"source":["# dataloaders\n","batch_size = 50\n","\n","# make sure the SHUFFLE your training data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"jv0Tzv0_2Nxs"},"source":["## **3. Build Model** "]},{"cell_type":"markdown","metadata":{"id":"M2swj0ud2gcj"},"source":["### **3.0. Check if GPU is Available**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1643851874911,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"dt0hUkKH2JXL","outputId":"20536ca2-bd9b-4dad-d309-280d9d681f0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, training on CPU.\n"]}],"source":["train_on_gpu=torch.cuda.is_available()\n","\n","if(train_on_gpu):\n","    print('Training on GPU.')\n","else:\n","    print('No GPU available, training on CPU.')"]},{"cell_type":"markdown","metadata":{"id":"T_0ZTEfY2ur4"},"source":["### **3.1. Construct a LSTM Class**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSuH8icU2r5W"},"outputs":[],"source":["class LSTM(nn.Module):\n","\n","\n","    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers):\n","        \"\"\"\n","        Initialize the model by setting up the layers.\n","        \"\"\"\n","        super(LSTM, self).__init__()\n","\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n","\n","        # dropout layers\n","        self.dropout = nn.Dropout(0.2)\n","\n","        # linear and sigmoid layers\n","        self.fc = nn.Linear(hidden_dim, 256)\n","        self.sig = nn.Sigmoid()\n","\n","\n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # embeddings and lstm_out\n","        x = x.long()\n","        embeds = self.embedding(x)\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","    \n","        # stack up lstm outputs\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        out = self.dropout(lstm_out)\n","        \n","        # dropout and fully-connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        # sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        return sig_out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n","                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n","        \n","        return hidden"]},{"cell_type":"markdown","metadata":{"id":"w_Mlt9Hh259l"},"source":["### **3.2. Initialize the Model** "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1643851874911,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"WGV9UaMT23p4","outputId":"81b352fc-a726-4fc4-adc2-d167bee0d6e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["LSTM \n"," LSTM(\n","  (embedding): Embedding(30001, 100)\n","  (lstm): LSTM(100, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc): Linear(in_features=256, out_features=256, bias=True)\n","  (sig): Sigmoid()\n",")\n"]}],"source":["vocab_size = len(word_to_int) + 1 # +1 for the 0 padding + our word tokens\n","output_size = 1\n","embedding_dim = 100\n","hidden_dim = 256\n","n_layers = 2\n","\n","sentiment_LSTM = LSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","print('LSTM \\n', sentiment_LSTM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQw-TDro3mqg"},"outputs":[],"source":["# loss and optimization functions\n","learning_rate = 0.0005\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(sentiment_LSTM.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"37ooMlV44330"},"source":["## **4. Train Model** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8S1pvjk4zb2"},"outputs":[],"source":["#functions used for training models\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","def save_model(filename, decoder):\n","    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n","    torch.save(decoder, save_filename)\n","\n","def load_model(filename):\n","    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n","    return torch.load(save_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvSYXwJiahXS"},"outputs":[],"source":["# training params\n","\n","epochs = 1 # 3-4 is approx where I noticed the validation loss stop decreasing\n","\n","counter = 0\n","print_every = 100\n","clip = 5 # gradient clipping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ur9dPC_ayDx"},"outputs":[],"source":["#lists used for plotting losses\n","step_list = list()\n","train_loss_list = list()\n","val_loss_list = list()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_nOtc5Va0TU"},"outputs":[],"source":["#use min_loss to track the best model throughout the training loop\n","min_val_loss = math.inf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbWgsE3Gaqt1"},"outputs":[],"source":["# move model to GPU, if available\n","if(train_on_gpu):\n","   sentiment_LSTM.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1643851875420,"user":{"displayName":"Uyen Le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbMvwFhO24j0GJLXKoG8ZNXvkmgaUxw0Dz4Fxeow=s64","userId":"14011474571632892466"},"user_tz":300},"id":"6l2PO1lyLDu4","outputId":"03cc3397-50bf-499f-c997-7c955263147b"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["train_on_gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YqQEGQbY47Aj","outputId":"628143cc-0b6c-4943-c4c8-2284c5e8ba22"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-1dea3dc94866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["sentiment_LSTM.train()\n","\n","# train for some number of epochs\n","for e in range(epochs):\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(e + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    # initialize hidden state\n","    h = sentiment_LSTM.init_hidden(batch_size)\n","\n","    # batch loop\n","    for inputs, labels in train_loader:\n","        counter += 1\n","\n","        if(train_on_gpu):\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","\n","        # zero accumulated gradients\n","        sentiment_LSTM.zero_grad()\n","\n","        # get the output from the model\n","        inputs = inputs.type(torch.LongTensor)\n","        output, h = sentiment_LSTM(inputs, h)\n","\n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","\n","        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(sentiment_LSTM.parameters(), clip)\n","        optimizer.step()\n","\n","        # loss stats\n","        if counter % print_every == 0:\n","            # Get validation loss\n","            val_h = sentiment_LSTM.init_hidden(batch_size)\n","            val_losses = []\n","            sentiment_LSTM.eval()\n","            for inputs, labels in valid_loader:\n","\n","                # Creating new variables for the hidden state, otherwise\n","                # we'd backprop through the entire training history\n","                val_h = tuple([each.data for each in val_h])\n","\n","                if(train_on_gpu):\n","                    inputs, labels = inputs.cuda(), labels.cuda()\n","\n","                inputs = inputs.type(torch.LongTensor)\n","                output, val_h = sentiment_LSTM(inputs, val_h)\n","                val_loss = criterion(output.squeeze(), labels.float())\n","\n","                val_losses.append(val_loss.item())\n","\n","            sentiment_LSTM.train()\n","            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                  \"Step: {}...\".format(counter),\n","                  \"Loss: {:.6f}...\".format(loss.item()),\n","                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0yE5fnEz4-t-"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"LSTM_Movie_Sentiments.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}